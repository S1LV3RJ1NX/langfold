name: langfold

services:
  redis:
    image: redis:6-alpine
    container_name: langfold-redis
    pull_policy: if_not_present
    command: redis-server --requirepass ${REDIS_PASSWORD:-password} --port ${REDIS_PORT:-6379}
    ports:
      - "${REDIS_PORT:-6380}:6380"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 60s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
    networks:
      - langfold-network

  litellm:
    # For issues with prisma binaries use:
    # https://docs.litellm.ai/docs/proxy/deploy#litellm-without-internet-connection
    image: ghcr.io/berriai/litellm:main-v1.51.2
    pull_policy: if_not_present
    container_name: langfold-litellm
    restart: unless-stopped
    ports:
      - "${LITELLM_PORT:-4120}:4120"
    expose:
      - "${LITELLM_PORT:-4120}"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4120/health/liveness"]
      interval: 60s
      timeout: 5s
      retries: 3
    volumes:
      - ./configs/litellm_config.yaml:/app/config.yaml
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1"
    environment:
      - LITELLM_LOG=DEBUG
      - REDIS_URL=${REDIS_URL}
    command:
      ["--config", "/app/config.yaml", "--port", "4120", "--num_workers", "2"]
    networks:
      - langfold-network

  langfold:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - ENV=local
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LITELLM_GATEWAY_URL=${LITELLM_GATEWAY_URL}
      - LITELLM_GATEWAY_API_KEY=${LITELLM_GATEWAY_API_KEY}
      - REDIS_URL=${REDIS_URL}
    container_name: langfold-backend
    ports:
      - "${LANGFOLD_PORT:-21120}:21120"
    volumes:
      - .:/app
      - /app/.venv
      - models_cache:/app/cache
    networks:
      - langfold-network

networks:
  langfold-network:
    external: false

volumes:
  models_cache:
