from langchain_core.runnables import RunnableConfig
from src.models.state import AgentState
from src.services.llm import MODEL


async def call_model(
    state: AgentState,
    config: RunnableConfig,
):
    """
    Asynchronously invokes the language model with the provided messages and configuration.

    This function takes the current state of the agent, which includes the messages to be processed,
    and a configuration object that may contain additional parameters for the invocation.

    Args:
        state (AgentState): The current state of the agent, which includes the messages to be sent to the model.
        config (RunnableConfig): Configuration settings for the invocation, which may include options like
                                 temperature, max tokens, etc.

    Returns:
        dict: A dictionary containing the model's response wrapped in a 'messages' key. The response is
              expected to be a single message generated by the model based on the input messages.
    """
    # Invoke the language model asynchronously with the messages from the state and the provided configuration
    response = await MODEL.ainvoke(state["messages"], config)

    # Return the response in a structured format, wrapping it in a list under the 'messages' key
    return {"messages": [response]}
